<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Columbia DSI Scholars</title>
    <link>/tags/python/</link>
    <description>Recent content in Python on Columbia DSI Scholars</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Sep 2020 00:00:00 +0000</lastBuildDate><atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>California&#39;s Water Data Challenge: Generating User-guided Prediction of Water Supply in the Californian Rivers</title>
      <link>/2020/09/project-californias-water-data-challenge-generating-user-guided-prediction-of-water-supply-in-the-californian-rivers/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-californias-water-data-challenge-generating-user-guided-prediction-of-water-supply-in-the-californian-rivers/</guid>
      <description>&lt;p&gt;Freshwater supply is critical for managing and meeting human and ecological demands. However, while stocks of water in both natural and artificial reservoirs are helpful for increasing availability, droughts and floods, as well as whiplash events affect reliability on these systems, posing grave consequences on water users. This risk is particularly salient in the state of California, where many local communities have been plagued by extreme hydrological events. In this current research, we contribute to California&amp;rsquo;s Water Data Challenge effort where a diverse group of volunteers convened to form a multi-disciplinary team that addresses the crucial issues of extreme events in California using data science approaches. Members include researchers and professionals who come from a range of backgrounds representing academia and private sectors. We combine a range of publicly available datasets with Machine Learning (ML) techniques to explore predictability of extreme events during California’s water years. More specifically, we use a variety of water districts and showcase how ML prediction models are not only able to predict the flow of water at varying time horizons, they capture uncertainties posed by the climate and human influences.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>China&#39;s War on Poverty</title>
      <link>/2020/09/project-chinas-war-on-poverty/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-chinas-war-on-poverty/</guid>
      <description>&lt;p&gt;In 2013, the Chinese government launched its grand initiative to eradicate rural poverty by 2020. The initiative has made great progress since then, yet little rigorous empirical evidence is available due to data limitations. This project aims to use big data through both official and social media to analyze the trends, achievements, and challenges of this initiative and offer implications for the future and from a comparative perspective.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Data For Good: African North Americans Database</title>
      <link>/2020/09/project-dfg-african-north-americans-database/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-dfg-african-north-americans-database/</guid>
      <description>&lt;p&gt;This project is the first comprehensive examination of African North Americans who crossed one of the U.S.-Canada borders, going either direction, after the Underground Railroad, in the generation alive roughly 1865-1930. It analyzes census and other records to match individuals and families across the decades, despite changes or ambiguities in their names, ages, &amp;ldquo;color,&amp;rdquo; birthplace, or other details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Decode the DNA Methylation in Memory</title>
      <link>/2020/09/project-decode-the-dna-methylation-in-memory/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-decode-the-dna-methylation-in-memory/</guid>
      <description>&lt;p&gt;Memory is a basic function of our brain that enables us to use the past experiences to service the present and future on a daily base, and memory function is often disrupted in neurological and psychiatric diseases, such as Alzheimer’s disease and posttraumatic stress disorder. To understand the molecular mechanism of memory storage, we will focus on DNA methylation, a chemical modification of our genome, that is hypothesized to play a critical role for memory. We have identified thousands of DNA methylation changes at numerous genomic loci occurred during the formation of fear and reward memory in the mouse brain. We will develop new computational tools to analyze these changes of DNA methylation and search for the common sequence features of these genomic loci. The result of this project will lead to a systematic understanding of the principle on the function and regulation of DNA methylation in memory, and will pave the way to develop new therapeutic strategies for diseases involved memory defects.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Defining Aneuploidy from Next-Gen Sequencing</title>
      <link>/2020/09/project-defining-aneuploidy-from-next-gen-sequencing/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-defining-aneuploidy-from-next-gen-sequencing/</guid>
      <description>&lt;p&gt;Our lab is interested in aneuploidy, or the incorrect number of whole chromosomes and chromosome arms. A challenge in this area of research is that karyotypes require a large number of proliferating cells for analysis. To address this, our lab and collaborators developed new algorithms to identify aneuploidy alterations from DNA sequencing data. Here, the project goal is to implement these algorithms at Columbia, and subsequently to apply these analysis methods to samples generated in the lab and patient samples. Building on this, the DSI student may also develop new algorithms for use with single-cell sequencing data and RNA sequencing data. Experience in one or more of the following is a must: UNIX, R, and python. The DSI student will be mentored by Dr. Alison Taylor, and he/she will also work closely with all lab members.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Generating a graph representation of microbial community diversity</title>
      <link>/2020/09/project-generating-a-graph-representation-of-microbial-community-diversity/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-generating-a-graph-representation-of-microbial-community-diversity/</guid>
      <description>&lt;p&gt;Understanding the interaction between human-associated microbial communities and human health is expected to revolutionize healthcare. Recent work found that this interaction is, in part, shaped by genetic differences between otherwise identical species in the microbiome. Detecting this variation, however, is a significant challenge. This project aims to profile microbial genetic variation within and across multiple patients&#39; microbiomes. This will allow us to better compare and interpret this variation in the context of human disease, gaining mechanistic insight into complex human-microbiome interactions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Improving observed and modeled air pollution data quality over sub-Saharan Africa using machine learning</title>
      <link>/2020/09/project-improving-observed-and-modeled-air-pollution-data-quality-over-sub-saharan-africa-using-machine-learning/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-improving-observed-and-modeled-air-pollution-data-quality-over-sub-saharan-africa-using-machine-learning/</guid>
      <description>&lt;p&gt;The goal of the project is twofold: 1) to better understand and further improve the use of low cost air pollution sensors and 2) to analyze and characterize air pollution data in sub-Saharan Africa. Air pollution kills an estimated 700,000 people per year in Africa, but existing air pollution data in Africa is extremely sparse and estimates of the associated mortality are uncertain. Low cost air pollution sensors have the potential to rapidly revolutionize air quality awareness and data availability in data-sparse areas of  the world, including sub-Saharan Africa. However, use of low cost sensors requires careful calibration, performance evaluation, and other quality assurance before the data can be fully trusted to the same degree as regulatory-grade monitors. As part of a larger project led by Dr. Westervelt, fine particulate matter (PM2.5) sensors have already been deployed in several African megacities, including Kinshasa, Democratic Republic of Congo; Nairobi, Kenya; Kampala, Uganda; Accra, Ghana, and Lomé, Togo. In Kampala and Accra, sensors are co-located with a regulatory-grade PM2.5 instrument for several months, allowing for a direct comparison between low cost and regulatory-grade PM2.5 measurements, and also allowing for the development of calibration factors.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Measuring Liberal Arts: Creating an Index for Higher Education</title>
      <link>/2020/09/project-measuring-liberal-arts-creating-an-index-for-higher-education/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-measuring-liberal-arts-creating-an-index-for-higher-education/</guid>
      <description>&lt;p&gt;This project works with a novel corpus of text-based school data to develop a multi-dimensional measure of the degree to which American colleges and universities offer a liberal arts education. We seek a data scientist for various tasks on a project that uses analysis of multiple text corpora to better understand the liberal arts. This is an ongoing three-year project with opportunities for future collaborations, academic publications, and developing and improving existing data science and machine learning skills. Tasks likely include: (1) Using Amazon Web Services to create and maintain cloud-based storage (SQL, S3 buckets) of the project&amp;rsquo;s expanding library of data. (2) Extracting information (named entities, times, places, books, and so on) from millions of plain-text syllabus records. (3) Merging multiple forms of data into a single dataset. (4) Scraping websites for relevant information (e.g., college course offerings, school rankings). Some pages may include dynamically created content that requires the use of a program such as Selenium.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Measuring the network impact of COVID-19</title>
      <link>/2020/09/project-measuring-the-network-impact-of-covid-19/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-measuring-the-network-impact-of-covid-19/</guid>
      <description>&lt;p&gt;The spread of COVID-19 has led to unprecedented and ongoing changes to daily life, including shelter-in-place orders, widespread closing of businesses and schools, and work-from-home and school-from-home at previously unknown levels. These changes in behavior are placing extraordinary demands on the Internet. This project will measure the Internet’s ability to meet these demands, including comparing its performance before, during, and after the peak of COVID-19; whether the amount of change varies between areas heavily impacted by COVID-19 and those less impacted; and whether and how large networks adapt. To provide this rich understanding, this project will combine multiple Internet-scale datasets that provide complementary views to investigate how responses to COVID-19 have impacted the Internet and how networks have reacted. Measuring the network impact of COVID-19 will illuminate the Internet’s strengths and weak points and is a crucial step towards improving the Internet’s future resilience in the face of pandemics, natural disasters, large scale conflict, and terrorist attacks.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Physically-informed polycrystal plasticity models of beta-HMX</title>
      <link>/2020/09/project-physically-informed-polycrystal-plasticity-models-of-beta-hmx/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-physically-informed-polycrystal-plasticity-models-of-beta-hmx/</guid>
      <description>&lt;p&gt;Traditionally, these types of data are routinely neglected in hand-crafted constitutive models due to the complexity. Instead, descriptors such as void fraction, dislocation density, and other statistical measures of the microstructures are often incorporated into yield surface or hardening rules (e.g. Gurson damage model, critical state plasticity). In this work, we will overcome this technical barrier by using a deep convolutional neural network to deduce low-dimensional descriptors that best describes the physics of the deformation process of polycrystals. With deep Q reinforcement learning to automate the trial-and-error process, we may explore the decision tree with a large number of trials that are impossible to be done manually. This treatment will empower us to discover the underlying mechanics of polycrystals under a variety of pressure, temperature, and loading rates highly relevant to the Air Force applications. While previous work on data-driven models has often focused on complete substitutions of constitutive laws with a data-driven paradigm, I intend to seek the best option representing the hierarchy of material responses, while implementing adversarial attacks to determine hidden weaknesses of existing polycrystal plasticity models as well as the one generated from the ML approaches. I will make use of a collocation Fast Fourier Transformation (FFT) solver to speed up the generations of the material database, digesting microstructural data via descriptors in the non-Euclidean space, Graph-based knowledge abstraction, and adversarial attack.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Prediction of microbial communities metabolic output</title>
      <link>/2020/09/project-prediction-of-microbial-communities-metabolic-output/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-prediction-of-microbial-communities-metabolic-output/</guid>
      <description>&lt;p&gt;The human microbiome is associated with different diseases, but the metabolic mechanisms through which it can modulate health are mostly unknown. Understanding these mechanisms is of paramount importance for prevention and treatment. While metagenomics analysis provides associations between microbial presence and specific diseases, metabolomics analysis can highlight metabolic alterations. None of the two, however, can unveil microbiome metabolic mechanisms associated with these detected alterations. In an attempt to fill this knowledge gap, several microbiome metabolic modeling methods were recently developed. An accurate evaluation of the accuracy of such methods in relation to different pathologies and microbiomes was never conducted.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Single cell RNA-seq analysis of eye development and disease</title>
      <link>/2020/09/project-single-cell-rna-seq-analysis-of-eye-development-and-disease/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-single-cell-rna-seq-analysis-of-eye-development-and-disease/</guid>
      <description>&lt;p&gt;Single cell sequencing has generated unprecedented insight into the cellular complexity of normal and diseased organ. We are interested in using this technique to understand the mechanisms of eye development, disease and regeneration. We also would like to compare the transcriptomic signatures between mouse models and human tissues. This project involves analysis of large amount of data from single cell sequencing. It requires understanding of statistical analysis and proficient programming skills.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Single-nucleus and spatial transcriptomics analysis of APOE mouse and human brain samples</title>
      <link>/2020/09/project-single-nucleus-and-spatial-transcriptomics-analysis-of-apoe-mouse-and-human-brain-samples/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-single-nucleus-and-spatial-transcriptomics-analysis-of-apoe-mouse-and-human-brain-samples/</guid>
      <description>&lt;p&gt;We are conducting a large-scale study analyzing brain tissues from mice and humans with different APOE genotypes, using both single-nucleus sequencing and spatial transcriptomics to assess RNA expression differences caused by APOE genotype. We are working with an expert bioinformatics core, but would like a data science student to help perform the analyses and act as an in-lab lead for the bioinformatics analysis. Prior experience analyzing RNA-sequencing data is preferred, but not required.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Using ICESat 2 satellite laser altimetry to track storms in Antarctica</title>
      <link>/2020/09/project-using-icesat-2-satellite-laser-altimetry-to-track-storms-in-antarctica/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-using-icesat-2-satellite-laser-altimetry-to-track-storms-in-antarctica/</guid>
      <description>&lt;p&gt;The main goal of this work is to assess if storms have increased in frequency over Antarctica. It is theorized that climate change will increase the intensity of the winds and frequency of the storms. With ICESat 2 satellite laser altimetry, we can count the number of storms and blowing snow events. ICESat 2 is a photon counting laser and generates terrabytes of data each day. Innovative data science techniques are needed to handle the data and analyze it. This project is, therefore, a suitable topic for a masters student that combines an important problem in Geophysics and climate science with a great Data Science application.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Using machine learning to understand tropical cyclone genesis pathways</title>
      <link>/2020/09/project-using-machine-learning-to-understand-tropical-cyclone-genesis-pathways/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/project-using-machine-learning-to-understand-tropical-cyclone-genesis-pathways/</guid>
      <description>&lt;p&gt;Until today there is no comprehensive theory for formation of tropical cyclones (hurricanes, typhoons). Therefore, it is common to use statistical methods to derive empirical indices as proxies for the probability for genesis. There are also different types of genesis pathways that have been explored in ad-hoc manner. I would like to explore the possibility of using machine learning to explore tropical cyclone genesis, in particular the different pathways in a more comprehensive manner.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Analysis and processing of GIS data in assessing international development</title>
      <link>/2020/05/project-analysis-and-processing-of-gis-data-in-assessing-international-development/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/05/project-analysis-and-processing-of-gis-data-in-assessing-international-development/</guid>
      <description>&lt;p&gt;We need someone with strong data wrangling capabilities, to be able to determine quick ways to clean and merge data. The format of the data is spatial (GIS) but it could also be manipulated in tabular format. GRID3 is a program within &lt;a href=&#34;http://www.ciesin.org/&#34;&gt;CIESIN&lt;/a&gt; which is a research center located at the Lamont-Doherty Campus (with office space on the morningside campus) and is part of Columbia&amp;rsquo;s Earth Institute.  Candidates can learn more about the program at the GRID3 &lt;a href=&#34;https://grid3.org/&#34;&gt;website&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Augmented Supervised Topic Models</title>
      <link>/2020/05/project-augmented-supervised-topic-models/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/05/project-augmented-supervised-topic-models/</guid>
      <description>&lt;p&gt;In this project we&amp;rsquo;ll be expanding on the existing family of supervised topic models. These models extend LDA to document collections where, for each document, we observe additional labels or values of interest. More specifically, one of the goals of this project is to use additional document level data, such as author information, to develop better exploratory data tools.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Characterizing network behavior in phishing emails</title>
      <link>/2020/05/project-characterizing-network-behavior-in-phishing-emails/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/05/project-characterizing-network-behavior-in-phishing-emails/</guid>
      <description>&lt;p&gt;Targeted phishing is one of the most common and damaging cybersecurity attacks, incurring tens of billions of dollars in losses a year. In order to increase the success of the phishing emails, attackers often craft emails that impersonate real people or legitimate online services, and send them from networks and hosting sites that have a high reputation. This leads major email security services, including Outlook and Gmail, to often misclassify these emails as legitimate.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Machine-learning based methods to extract river flow information from satellite imagery</title>
      <link>/2020/05/project-machine-learning-based-methods-to-extract-river-flow-information-from-satellite-imagery/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/05/project-machine-learning-based-methods-to-extract-river-flow-information-from-satellite-imagery/</guid>
      <description>&lt;p&gt;Humanity thrives along major rivers – this is as true now as it was ages ago. Our dependence on rivers for agriculture and electricity, as well as the need to control its flow because of our proximity, has  resulted in dramatic changes to the nature of the rivers. What were once great perennial rivers are now mere trickles during the summer months. This puts the livelihood of many people, especially poor farmers, in jeopardy. How can we monitor and document changes to the flow through rivers over time? Since river gauge measurements are rare or non-existent, any way in which we can use freely available satellite imagery (Landsat, Sentinel) to determine the changes in flow patterns of rivers over time would be extremely useful. One such tool is Rivamap – it uses OpenCV to analyze satellite imagery to extract information about rivers, especially for large rivers. What about smaller ones – it does not seem to work as well. In this project, the student(s) will have to develop machine-learning based methods  (or extend the capabilities of Rivamap) to study satellite images to extract information about the path and dimensions of rivers of different flow rates and flow patterns. Comparison with ground-truth data will be needed.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Phenotyping COVID-19 patients using NLP and clinical notes</title>
      <link>/2020/05/project-phenotyping-covid-19-patients-using-nlp-and-clinical-notes/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/05/project-phenotyping-covid-19-patients-using-nlp-and-clinical-notes/</guid>
      <description>&lt;p&gt;Our lab is using clinical notes to phenotype COVID patient outcomes. The aim is to better understand the sequela of COVID-19 from clinical notes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Social media echo chambers enhancing anxiety and depression: the effects of COVID-19</title>
      <link>/2020/05/project-social-media-echo-chambers-enhancing-anxiety-and-depression-the-effects-of-covid19/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/05/project-social-media-echo-chambers-enhancing-anxiety-and-depression-the-effects-of-covid19/</guid>
      <description>&lt;p&gt;The question we ask is whether online echo-chambers on social media networks enhance the anxiety and depression of individuals during the COVID19 outbreak. More specifically we want to measure the intensity of the communication about COVID-19 within the echo-chamber of individuals on Twitter and investigate the impact on their subsequent tweets in terms of the level of anxiety and signs of depressive language in their Tweets.  We measure echo-chambers by the number of users in the social network that tweeted about COVID-19. We build on an extensive dataset of Twitter users for whom we have identified a large number of demographic and geographic variables (such as the gender, age, ethnicity, location by state, political affiliation) as well as their social network.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cryptocurrency Analytics: Identifying Bad Actors</title>
      <link>/2020/02/project-cryptocurrency-analytics-identifying-bad-actors/</link>
      <pubDate>Thu, 20 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/02/project-cryptocurrency-analytics-identifying-bad-actors/</guid>
      <description>&lt;p&gt;Many of the cryptocurrency transactions have involved fraudulent activities including ponzi schemes, ransomware as well money-laundering. The objective is to use Graph Machine Learning methods to identify the miscreants on Bitcoin and Etherium Networks. There are many challenges including the amount of data in 100s of Gigabytes, creation and scalability of algorithms.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Understanding Orientation</title>
      <link>/2020/02/project-understanding-orientation/</link>
      <pubDate>Thu, 20 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/02/project-understanding-orientation/</guid>
      <description>&lt;p&gt;Orienting to a novel event is a rapid shift in attention to a change in one’s surroundings that appears to be a fundamental biological mechanism for survival and essentially functions as a &amp;ldquo;what is it&amp;rdquo; detector. Orienting appears to play a central role in human learning and development, as it facilitates adaptation to an ever-changing environment.  Thus, orienting can be viewed as an allocational mechanism in which attention sifts through the complex multi-sensory world and selects relevant stimuli for further processing.  The selection of stimuli for further processing has implications for what will be encoded into memories and how strong those memory traces will be.  The ability to differentiate between relevant and irrelevant input, to inhibit the processing of irrelevant stimuli, and to sustain attention requires control, and inhibitory processes that improve with age.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Advanced data science methods to improve spinal electrical stimulation for paralysis</title>
      <link>/2020/01/project-advanced-data-science-methods-to-improve-spinal-electrical-stimulation-for-paralysis/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-advanced-data-science-methods-to-improve-spinal-electrical-stimulation-for-paralysis/</guid>
      <description>&lt;p&gt;We aim to augment recovery in spinal cord (SC) injured patients. Electrical stimulation of the SC can facilitate recovery, but the mechanisms are not yet understood. One knowledge gap lies in the exact pathways that are recruited by stimulation. To close this gap, we have tested the effects of SC stimulation in people undergoing clinically indicated surgery. By testing the distribution and size of muscle responses to SC stimulation, we can infer which circuits are activated. We are also examining how SC injury changes those responses. We propose to use Bayesian methods to understand the  interaction between muscle responses to stimulation and the MRI indicated pattern of damage. The project will involve construction of models linking multiple data modalities that predict muscle activity, followed by the modification of these models to account for patterns of damage. Construction of such models would enable a deeper understanding of SC stimulation leading to more effective stimulation paradigms.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Combining in vivo calcium imaging datasets and deep learning networks for video analysis (DeepLabCut) to identify novel brain regulators of fine motor learning in mice</title>
      <link>/2020/01/project-combining-in-vivo-calcium-imaging-datasets-and-deep-learning-networks-for-video-analysis-deeplabcut-to-identify-novel-brain-regulators-of-fine-motor-learning-in-mice/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-combining-in-vivo-calcium-imaging-datasets-and-deep-learning-networks-for-video-analysis-deeplabcut-to-identify-novel-brain-regulators-of-fine-motor-learning-in-mice/</guid>
      <description>&lt;p&gt;Our goal is to use deep learning networks to understand which neurons in the brain encode fine motor movements in mice. We collected large datasets entailing calcium imaging data of active neurons and high-resolution videos when mice perform motor tasks. We want to use recent advances in deep learning to (1) estimate the poses of mouse body parts at a high spatiotemporal resolution (2) extract behaviorally-relevant information and (3) align them with neural activity data. Behavioral video analysis is made possible by transfer learning, the ability to take a network that was trained on a task with a large supervised dataset and utilize it on a small supervised dataset. This has been used e.g. in a human pose–estimation algorithm called DeeperCut. Recently, such algorithms were tailored for use in the laboratory in a Python-based toolbox known as DeepLabCut, providing a tool for high-throughput behavioral video analysis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Data For Good: Data Analysis for a Just Transition in Energy for Thermal Comfort</title>
      <link>/2020/01/project-data-analysis-for-a-just-transition-in-energy-for-thermal-comfort/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-data-analysis-for-a-just-transition-in-energy-for-thermal-comfort/</guid>
      <description>&lt;p&gt;42% of New York City greenhouse gas emissions result from on-site fossil fuel combustion in residential and commercial buildings; space heating is, by far, the majority contributor. Both New York State and NYC have policies to dramatically reduce emissions that will require a transformation in the way buildings are heated, including major efforts in existing buildings. This transition is inextricably linked to existing energy equity issues that we believe significantly overlap across NYC (and elsewhere). These include unreliable heating in the winter, susceptibility to extreme heat (an increasing occurrence with climate change) and struggles to afford energy needs. Various known data sources for NYC are available, though they are disparate and have not been analyzed holistically. Further, we believe there are potential engineering and policy solutions to these challenges. In this project, the DSI scholar will access (and search for where not yet known to qSEL researchers) relevant data sets, analyze those data sets to identify communities exposed to all or a subset of these issues, and assist qSEL researchers in developing models to evaluate possible solutions. The project has the possibility of extending through Summer 2020, subject to fundraising efforts and the success of the Spring 2020 project.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Decoding the human genome with interpretable deep learning </title>
      <link>/2020/01/project-decoding-the-human-genome-with-interpretable-deep-learning/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-decoding-the-human-genome-with-interpretable-deep-learning/</guid>
      <description>&lt;p&gt;The function for much of the 3 billion letters in the human genome remain to be understood. Advances in DNA sequencing technology have generated enormous amount of data, yet we don’t have the tool to extract rules of how the genome works. Deep learning holds great potential in decoding the genome, in particular due to the digital nature of DNA sequences and the ability to handle large data sets. However, like many other applications, the interpretability of deep learning models hampers its ability to help understand the genome. We are developing deep learning architectures embedded with the principles of gene regulation and we will be leveraging billions of existing measurements of gene activity to learn a mechanistic model of gene regulation in human cells.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Deep learning for tracking single molecules and proteins</title>
      <link>/2020/01/project-deep-learning-for-tracking-single-molecules-and-proteins/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-deep-learning-for-tracking-single-molecules-and-proteins/</guid>
      <description>&lt;p&gt;This project will be focused on creating a deep learning framework for tracking individual molecules and proteins as they move within a cell under various conditions. Using total internal reflection (TIRF) microscopy, we have accumulated more than 10 million trajectories over dozens of experimental preparations with differences in both the imaging approaches as well as the biological context. In our experiments we have captured particles under a wide variety of conditions including increased protein expression level, and a range of drug concentrations. Our biggest challenge is being able to stably track the movement of a particle as it passes by other particles or groups of particles, and to do this in a way that generalizes over novel conditions. The Data Science Institute Scholar chosen for this project would work with scientists in the Javitch laboratory and others across the Columbia campus to conceive of an approach for efficiently and effectively tracking particles. The resulting work would be of great interest to an increasing number of scientists working in this field who currently rely on methods based on feature engineering that are often inaccurate or inflexible compared to modern deep learning methods.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Efficient representations and prediction of multidimensional time series data</title>
      <link>/2020/01/project-efficient-representations-and-prediction-of-multidimensional-time-series-data/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-efficient-representations-and-prediction-of-multidimensional-time-series-data/</guid>
      <description>&lt;p&gt;Big data with temporal dependence brings unique challenges in effective prediction and data analysis. The complex high-dimensional interactions between observations in such data brings unique challenges which standard off-the-shelf machine learning algorithms cannot handle. Even basic tasks of clustering, visualization and identification of recurring patterns are difficult.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Evaluating Reconstructions of the Ocean Carbon Sink</title>
      <link>/2020/01/project-evaluating-reconstructions-of-the-ocean-carbon-sink/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-evaluating-reconstructions-of-the-ocean-carbon-sink/</guid>
      <description>&lt;p&gt;The ocean significantly mitigates climate change by absorbing fossil fuel carbon from the atmosphere. Cumulatively since the preindustrial times, the ocean has absorbed 40% of emissions. To understand past changes, diagnose ongoing changes, and to predict the future behavior of the ocean carbon sink, we must understand its spatial and temporal variability. However, the ocean is poorly sampled and so we cannot do this from direct measurements.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Group Decision Making and Communication in Limitless Space</title>
      <link>/2020/01/project-group-decision-making-and-communication-in-limitless-space/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-group-decision-making-and-communication-in-limitless-space/</guid>
      <description>&lt;p&gt;The introduction of a new technology provides individuals and organizations with a large, unowned, and limitless space for communication and organization. How do individuals use or misuse this space in their decision making? Using online discussion platforms, we will analyze what types of discussions thrive - those with depth of discussion or topical complexity or those with cohesive contours? We’ll ask, are there high status actors who are particularly good at recognizing topic gaps which need new conversations? Using social psychological theories with a large-scale archival dataset, we’ll learn more about the impact of new technologies on group decision-making processes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>High Quality Video Streaming over Wireless</title>
      <link>/2020/01/project-high-quality-video-streaming-over-wireless/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-high-quality-video-streaming-over-wireless/</guid>
      <description>&lt;p&gt;The amount of video content that is being distributed over the Internet is increasing. Video providers rely on HTTP adaptive streaming approaches to deliver video clips to users. Complementary to the video provider, the service provider must determine the priority of each network stream. As part of the project, students will explore wireless network assisted strategies for http adaptive streaming by use of TOS/DSCP. This includes using machine-learning tools to analyze network video traffic and the design of reinforcement learning algorithms to improve users&#39; video Quality of Experience.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Influence of past brain state on future perception</title>
      <link>/2020/01/project-influence-of-past-brain-state-on-future-perception/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-influence-of-past-brain-state-on-future-perception/</guid>
      <description>&lt;p&gt;We are constantly exposed to inputs from the outside world, but we do not perceive everything we are exposed to. Some inputs are rather weak: we might perceive them at one point in time, but not at another. The state of our brains right before we receive such sensory inputs influences whether or not we perceive them. Brain oscillations are proposed to play a key role in setting these brain states; however, how exactly these brain rhythms influence our perception remains a topic of active research.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Single cell RNA-seq analysis of eye development and disease</title>
      <link>/2020/01/project-single-cell-rna-seq-analysis-of-eye-development-and-disease/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-single-cell-rna-seq-analysis-of-eye-development-and-disease/</guid>
      <description>&lt;p&gt;Single cell sequencing has generated unprecedented insight into the cellular complexity of normal and diseased organ. We are interested in using this technique to understand the mechanisms of eye development, disease and regeneration. We also would like to compare the transcriptomic signatures between mouse models and human tissues. This project involves analysis of large amount of data from single cell sequencing. It requires understanding of statistical analysis and proficient programming skills.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Statistical analyses of Siamese fighting fish aggressive behavior</title>
      <link>/2020/01/project-statistical-analyses-of-siamese-fighting-fish-aggressive-behavior/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-statistical-analyses-of-siamese-fighting-fish-aggressive-behavior/</guid>
      <description>&lt;p&gt;Project: analyze behavior of Siamese fighting fish (Betta splendens) as part of a collaboration between the Bendesky and Cunningham labs of the Zuckerman Institute (NeuroTheory Center)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Evolution of the Smallest Galaxies in the Universe</title>
      <link>/2020/01/project-the-evolution-of-the-smallest-galaxies-in-the-universe/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-the-evolution-of-the-smallest-galaxies-in-the-universe/</guid>
      <description>&lt;p&gt;The Milky Way swarms with orbiting satellite dwarf galaxies of astounding diversity. Some galaxies continue to form stars while others stop and dim in brightness. In computer simulations, the evolutionary history of each dwarf galaxy that leads to these differences is known. Galaxies can lose gas and stop forming stars due to early exposure to stellar radiation (reionization), interaction with the hot gas of the host (ram-pressure stripping), or gravitational interactions with the host/dwarf galaxies (tidal effects).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Urban Lead Atlas</title>
      <link>/2020/01/project-the-urban-lead-atlas/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-the-urban-lead-atlas/</guid>
      <description>&lt;p&gt;The Urban Lead Atlas is a collaborative community-based research initiative to create the nations’ first crowd-sourced open online map identifying toxic lead hazards located within the homes, schools, landscape, and lead service lines for water in American cities. The project will begin by integrating data from a small set of cities – New York, Philadelphia, Washington D.C. and Newark - including housing enforcement and lead service line datasets, data on lead dust in schools, and the results of soil lead tests in parks and backyards, on the websites of Columbia University’s Center for Sustainable Urban Development. Ultimately, the goal of the Urban Lead Atlas is to create and populate a fully open online platform that is capable of integrating data from “citizen scientists” and residents regarding the sites of lead hazards in their city’s environment and buildings. This research is important, as experts estimate that over nine million US children have lead blood levels which may cause sub-clinical effects and permanent adverse health, cognitive, and behavior outcomes. The Lead Atlas is intended as the first model for a national effort, the American Lead Atlas project, which seeks to create a national online collaborative map of lead hazards within American cities.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Data For Good: African North Americans Database</title>
      <link>/2020/01/project-dfg-african-north-americans-database/</link>
      <pubDate>Sat, 04 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/project-dfg-african-north-americans-database/</guid>
      <description>&lt;p&gt;This project is the first comprehensive examination of African North Americans who crossed one of the U.S.-Canada borders, going either direction, after the Underground Railroad, in the generation alive roughly 1865-1930. It analyzes census and other records to match individuals and families across the decades, despite changes or ambiguities in their names, ages, &amp;ldquo;color,&amp;rdquo; birthplace, or other details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cryptocurrency Analytics: Identifying Bad Actors</title>
      <link>/2019/09/project-cryptocurrency-analytics-identifying-bad-actors/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/project-cryptocurrency-analytics-identifying-bad-actors/</guid>
      <description>&lt;p&gt;Many of the cryptocurrency transactions have involved fraudulent activities including ponzi schemes, ransomware as well money-laundering. The objective is to use Graph Machine Learning methods to identify the miscreants on Bitcoin and Etherium Networks. There are many challenges including the amount of data in 100s of Gigabytes, creation and scalability of algorithms.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Decoding the human genome with interpretable deep learning</title>
      <link>/2019/09/project-decoding-the-human-genome-with-interpretable-deep-learning/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/project-decoding-the-human-genome-with-interpretable-deep-learning/</guid>
      <description>&lt;p&gt;The function for much of the 3 billion letters in the human genome remain to be understood. Advances in DNA sequencing technology have generated enormous amount of data, yet we don&amp;rsquo;t have the tool to extract rules of how the genome works. Deep learning holds great potential in decoding the genome, in particular due to the digital nature of DNA sequences and the ability to handle large data sets. However, like many other applications, the interpretability of deep learning models hampers its ability to help understand the genome. We are developing deep learning architectures embedded with the principles of gene regulation and we will be leveraging millions of existing whole genome measurements of gene activity to learn a mechanistic model of gene regulation in human cells.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Efficiently representing genetic diversity from thousands of microbiome samples</title>
      <link>/2019/09/project-efficiently-representing-genetic-diversity-from-thousands-of-microbiome-samples/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/project-efficiently-representing-genetic-diversity-from-thousands-of-microbiome-samples/</guid>
      <description>&lt;p&gt;The microbiome comprises a heterogeneous mix of bacterial strains, many with strong association to human diseases. Recent work has shown that even the same bacteria could have differences in their genomes across multiple individuals. Such differences, termed structural variations, are strongly associated with host disease risk factors [1]. However, methods for their systematic extraction and profiling are currently lacking. This project aims to make cross-sample analysis of structural variants from hundreds of individual microbiomes feasible by efficient representation of metagenomic data. The colored De-Bruijn graph (cDBG) data structure is a natural choice for this representation [2]. However, current cDBG implementations are either fast at the cost of a large space, or highly space efficient but either slow or lacking valuable practical features.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Integrated Traffic-Communication Simulator for COSMOS testbed</title>
      <link>/2019/09/project-integrated-traffic-communication-simulator-for-cosmos-testbed/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/project-integrated-traffic-communication-simulator-for-cosmos-testbed/</guid>
      <description>&lt;p&gt;Vehicle-to-Vehicle (V2V) has received increasing attention with the development of autonomous driving technology. It is believed that multi-vehicular and multi-informative algorithm is the direction of the autonomous driving technology. However, the stability and liability of the communication prevents the future from extensively embracing V2V-based transportation. Rigorous test is required before V2V can actually hit the road.  Compared with the costly field test, simulation tests are more economical and feasible.  To simulate the V2V communication and evaluate the robustness of current V2V-based algorithm, we are therefore developing a simulation platform integrating different commercial software like SUMO, Veins and OMNET++. These software simulate on the actual New York map, and simulate the vehicular communication in different scenarios and platoon configurations.  Our next step is to use this platform to test our own V2V-based algorithms. The output of this research will eventually provide an open platform which would automatically evaluate personally designed algorithm with least manual work.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Learning the most crucial features of the galaxy merger histories</title>
      <link>/2019/09/project-learning-the-most-crucial-features-of-the-galaxy-merger-histories/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/project-learning-the-most-crucial-features-of-the-galaxy-merger-histories/</guid>
      <description>&lt;p&gt;Galaxies in our universe form hierarchically, continuously merging and absorbing smaller galaxies over cosmic time. In this project we aim to identify the most important features of, as well as generate efficient new features from, the merger histories of galaxies. Namely, features that predict (or physically speaking, determine) the properties of galaxies, e.g. their shape or color. This will be done using the results from a large cosmological simulation, IllustrisTNG (&lt;a href=&#34;http://www.tng-project.org&#34;&gt;www.tng-project.org&lt;/a&gt;). We will begin with identifying ways to represent the rich information in the merger history. We will then compare various ML methods oriented towards feature selection or importance analysis: random forests or gradient boosted trees, L1SVM, neural networks (through analysis of e.g. saliency maps). More advanced models can also be applied, such as neural network models designed for feature selection. Finally, we wish to apply / develop methods that can build &amp;lsquo;interpretable&amp;rsquo; new features by constructing them as algebraic formulas from original input features (inspired by e.g. &lt;a href=&#34;https://science.sciencemag.org/content/324/5923/81)&#34;&gt;https://science.sciencemag.org/content/324/5923/81)&lt;/a&gt;. The overarching goal is to understand better what in the merger history is most crucial in determining a galaxy&amp;rsquo;s present-day properties, an answer to which can be widely applicable to problems in galaxy formation.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Measuring Liberal Arts: Creating an Index for Higher Education</title>
      <link>/2019/09/project-measuring-liberal-arts-creating-an-index-for-higher-education/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/project-measuring-liberal-arts-creating-an-index-for-higher-education/</guid>
      <description>&lt;p&gt;This project works with a novel corpus of text-based school data to develop a multi-dimensional measure of the degree to which American colleges and universities offer a liberal arts education. We seek a data scientist for various tasks on a project that uses analysis of multiple text corpora to better understand the liberal arts. This is an ongoing three-year project with opportunities for future collaborations, academic publications, and developing and improving existing data science and machine learning skills. Tasks likely include: (1) Using Amazon Web Services to create and maintain cloud-based storage (SQL, S3 buckets) of the project&amp;rsquo;s expanding library of data. (2) Extracting information (named entities, times, places, books, and so on) from millions of plain-text syllabus records. (3) Merging multiple forms of data into a single dataset. (4) Scraping websites for relevant information (e.g., college course offerings, school rankings). Some pages may include dynamically created content that requires the use of a program such as Selenium.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Single-Cell Transcriptome Profiling in Atherosclerosis</title>
      <link>/2019/09/project-single-cell-transcriptome-profiling-in-atherosclerosis/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/project-single-cell-transcriptome-profiling-in-atherosclerosis/</guid>
      <description>&lt;p&gt;Atherosclerosis—a chronic inflammatory disease of the artery wall—is the underlying cause of human coronary heart diseases. Cells within atherosclerotic lesions are heterogeneous and dynamic. Their pathological features have been characterized by histology and flow cytometry and more recently, by bulk-tissue omics profiling. Despite this progress, our knowledge of cell types and their roles in atherogenesis remains incomplete because of masking of differences across cells when using genomic measurement at bulk level. Single-cell RNA sequencing (scRNA-seq) has catalyzed a revolution in understanding of cellular heterogeneity in organ systems and diseases. This project applies scRNA-seq to define the genetic influences on cell subpopulations and functions in atherosclerotic lesion of transgenic mice for candidate risk genes of human coronary heart diseases as inspired by human genomic discoveries. The students involved in this project are expected to work on: (1) analysis of scRNA-seq data using R/Bioconductor packages; (2) Interpretation of the data using pathway and network analysis. Some relevant workflows are available through the &amp;ldquo;Resources&amp;rdquo; page of our lab website at &lt;a href=&#34;https://hanruizhang.github.io/zhanglab/&#34;&gt;https://hanruizhang.github.io/zhanglab/&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Waymo &amp; Lyft Driverless Car Data Analysis and Driving Modeling</title>
      <link>/2019/09/project-waymo-lyft-driverless-car-data-analysis-and-driving-modeling/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/project-waymo-lyft-driverless-car-data-analysis-and-driving-modeling/</guid>
      <description>&lt;p&gt;Autonomous driving is developing rapidly. A lot of breakthroughs of autonomous driving have emerged in both academy and industry. However, many traffic accidents related to autonomous driving also occur and cause people’s concern on the safety issue of AV. To ensure safety and reliability, rigorous test and simulation is required before AV can really drive on road. For AV test and simulation, realistic data is an essential component. Comprehensive, multi-regime and sufficient self-driving data would definitely help the AV development.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: A Data-driven Approach for Improving the User Experience of Internet Users</title>
      <link>/2019/01/project-a-data-driven-approach-for-improving-the-user-experience-of-internet-users/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/project-a-data-driven-approach-for-improving-the-user-experience-of-internet-users/</guid>
      <description>&lt;p&gt;Our lives are heavily reliant on Internet-connected devices and services. However, to deliver the desired user experience over the Internet, network operators need to detect and diagnose various network events (e.g., disruption, outage, misconfiguration, etc.) as well as resolve them in real-time. We have developed an Internet-wide measurement infrastructure that collects performance metrics (e.g., latency, jitter, throughput, packet loss rate, signal strength, etc.) from vantage points deployed by real users (mobile phones, WiFi access points, etc.) at regular intervals.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Analysis and Prediction of Opioid Outbreak Clusters</title>
      <link>/2019/01/project-analysis-and-prediction-of-opioid-outbreak-clusters/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/project-analysis-and-prediction-of-opioid-outbreak-clusters/</guid>
      <description>&lt;p&gt;We are interested in investigating how deaths and hospitalizations resulting from opioid overdoses cluster across space and time in the US. This analysis will be conducted with the aid of two comprehensive databases: 1) detailed mortality data across the US; and 2) a stratified sample of all hospitalizations in the US, which can be subset to select for opioid overdoses. Analyses will be extended to drug type (prescription drugs, fentanyl etc.) and subject demographics (age, race, etc.). We have previously conducted similar cluster analysis for other health phenomena.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: ArXivLab: A Platform for Developing and Evaluating Exploratory Tools for the Scientific Literature</title>
      <link>/2019/01/project-arxivlab-a-platform-for-developing-and-evaluating-exploratory-tools-for-the-scientific-literature/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/project-arxivlab-a-platform-for-developing-and-evaluating-exploratory-tools-for-the-scientific-literature/</guid>
      <description>&lt;p&gt;Through ArXivLab we aim to develop the next generation recommender systems for the scientific literature using statistical machine learning approaches. In collaboration with ArXiv we are currently developing a new scholarly literature browser which will be able to extract knowledge implicit in the mathematical and scientific literature, offer advanced mathematical search capabilities and provide personalized recommendations.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Distance Metric Learning in Hyperbolic Spaces</title>
      <link>/2019/01/project-distance-metric-learning-in-hyperbolic-spaces/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/project-distance-metric-learning-in-hyperbolic-spaces/</guid>
      <description>&lt;p&gt;Effective representations and analyses of symbolic data, such as lexical data (words) and networks (graphs), have become of great interest in recent years, due both to advancements in data collection in Natural Language Processing (NLP), and the ubiquity of social networks. Such data often has no natural numerical representation, and is typically described in terms relational expressions or as pairwise similarities. It turns out that finding numerical representations of such data in “Hyperbolic” spaces&amp;mdash;rather than into the more familiar Euclidean spaces&amp;mdash;is a more effective way to preserve valuable relational information.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Enhancing Self-Directed Learning Opportunities Using Learning Analytics</title>
      <link>/2019/01/project-enhancing-self-directed-learning-opportunities/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/project-enhancing-self-directed-learning-opportunities/</guid>
      <description>&lt;p&gt;Analyze data from one or more of the following Library Applications/Systems and create visualizations that highlight the most important findings related to our goal of supporting self-directed learning.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Measuring Broadband</title>
      <link>/2019/01/project-measuring-broadband/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/project-measuring-broadband/</guid>
      <description>&lt;p&gt;The Federal Communications Commission (FCC) and the Census regularly publish data on U.S. Internet availability, performance and use, at granularities from census block to county and state. The project goal is to answer questions based on the available data, such as &amp;ldquo;How reliable is Internet access?&amp;rdquo;, &amp;ldquo;Who is deploying fiber where?&amp;rdquo;, &amp;ldquo;Can we predict reliability of different technologies?&amp;rdquo;, &amp;ldquo;Can we predict the deployment of fiber?&amp;rdquo;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Random Forest vs. Neural Networks for Estimating the Ocean Carbon Sink</title>
      <link>/2019/01/random-forest-vs-neural-networks-for-estimating-the-ocean-carbon-sink/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/random-forest-vs-neural-networks-for-estimating-the-ocean-carbon-sink/</guid>
      <description>&lt;p&gt;The ocean has absorbed the equivalent of 41% of industrial-age fossil carbon emissions. In the future, this rate of this ocean carbon sink will determine how much of mankind’s emissions remain in the atmosphere and drive climate change.  To quantify the ocean carbon sink, surface ocean pCO2 must be known, but cannot be measured from satellite; instead it requires direct sampling across the vast and dangerous oceans. Thus, there will never be enough observations to directly estimate the carbon sink as it evolves. Data science can fill this gap by offering robust approaches to extrapolate from sparse observations to full coverage fields given auxiliary data that can be measured remotely.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Blockchain Anomaly Detection</title>
      <link>/2019/01/project-blockchain-anomaly-detection/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/project-blockchain-anomaly-detection/</guid>
      <description>&lt;p&gt;The project has collected a large set of data (&amp;gt;200GB) from a cryptocurrency block chain.  It is developing methods for detecting anomalies in transactions based on newer Social Networks, Graph Analysis and Machine Learning methods. The work involves data cleaning/wrangling and creation and implementation of various algorithms and analyzing the transactions for identifying different set of anomalies and manipulations.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Learning Representations and Patterns in Mathematical Proofs </title>
      <link>/2019/01/project-learning-representations-and-patterns-in-mathematical-proofs/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/project-learning-representations-and-patterns-in-mathematical-proofs/</guid>
      <description>&lt;p&gt;A common challenge for students in heavy proof-based courses is to come up with a long sequence of logical arguments from the problem statement to the final solution. In doing so, they can often skip steps leading to logical leaps or downright incorrect solutions. Ideally the instructor should identify these mis-steps and help students master such proof-based course material. Here we want to take a data-driven approach to address this challenge.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Looking for the Weird in TESS</title>
      <link>/2019/01/project-looking-for-the-weird-in-tess/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/project-looking-for-the-weird-in-tess/</guid>
      <description>&lt;p&gt;Last year one of my graduate students developed a novel algorithm for detecting &amp;ldquo;weird&amp;rdquo; signals in photometric time series, such as those taken by NASA&amp;rsquo;s Kepler Mission and now TESS. An undergraduate students will work in my team to run the algorithm on TESS data, which is just starting to be released publicly (&lt;a href=&#34;https://heasarc.gsfc.nasa.gov/docs/tess/status.html)&#34;&gt;https://heasarc.gsfc.nasa.gov/docs/tess/status.html)&lt;/a&gt;. We hope to detect strange signatures, possibly including analogs to Tabby&amp;rsquo;s Star, interacting binaries and perhaps even technosignatures.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Measuring Liberal Arts: Creating an Index for Higher Education</title>
      <link>/2019/01/project-measuring-liberal-arts-creating-an-index-for-higher-education/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/project-measuring-liberal-arts-creating-an-index-for-higher-education/</guid>
      <description>&lt;p&gt;This project works with a novel corpus of text-based school data to develop a multi-dimensional measure of the degree to which American colleges and universities offer a liberal arts education. We seek a data scientist for various tasks on a project that uses analysis of multiple text corpora to better understand the liberal arts. This is an ongoing three-year project with opportunities for future collaborations, academic publications, and developing and improving existing data science and machine learning skills.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Quantifying Global Risks</title>
      <link>/2019/01/project-quantifying-global-risks/</link>
      <pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/project-quantifying-global-risks/</guid>
      <description>&lt;p&gt;In a globalized world we live in today consequences of catastrophic events easily transgress national borders. Whether it’s a natural disaster, a war or an economic crisis it’s likely to spread out and affect all of us. We propose a framework to model global risks that is not bound to any specific model and is a hybrid of human and machine intelligence. The core of this approach is in using Bayesian Nets of causalities constructed by an analyst equipped with text mining and a map of economic, political and business interconnections.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Technology transfer insights from data</title>
      <link>/2018/01/project-technology-transfer-insights-from-data/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/project-technology-transfer-insights-from-data/</guid>
      <description>&lt;p&gt;CTV’s core mission is to facilitate the transfer of inventions from academic labs to the market for the benefit of society. In a typical year, CTV receives ~400 inventions, completes ~100 licenses and options, and helps form ~20 startups. A good video summary of CTV is here: &lt;a href=&#34;https://vimeo.com/110193999&#34;&gt;https://vimeo.com/110193999&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Data Science and the regulation of financial markets (application closed)</title>
      <link>/2018/01/project-data-science-and-the-regulation-of-financial-markets/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/project-data-science-and-the-regulation-of-financial-markets/</guid>
      <description>&lt;p&gt;The development of computational data science
techniques in natural language processing (NLP) and machine
learning (ML) algorithms to analyze large and complex textual
information opens new avenues to study intricate processes,
such as government regulation of financial markets, at a scale
unimaginable even a few years ago. This project develops scalable
NLP and ML algorithms (classification, clustering and
ranking methods) that automatically classify laws into various
codes/labels, rank feature sets based on use case, and induce
best structured representation of sentences for various types of
computational analysis.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Enhancing self-directed learning opportunities</title>
      <link>/2018/01/project-enhancing-self-directed-learning-opportunities/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/project-enhancing-self-directed-learning-opportunities/</guid>
      <description>&lt;p&gt;Analyze data from one of the following library applications/systems and create visualizations that highlight the most important findings pertaining to the support of self-directed learning:  Vialogues (TC Video Discussion Application), PocketKnowledge (TC Online Archive), DocDel (E-Reserve System), Pressible (Blogging Platform), Library Website and Mobile App.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Genomic and environmental predictor of preterm birth</title>
      <link>/2018/01/project-genomic-and-environmental-predictor-of-preterm-birth/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/project-genomic-and-environmental-predictor-of-preterm-birth/</guid>
      <description>&lt;p&gt;Predicting preterm birth in nulliparous women is challenging and our efforts to develop predictors for that condition from environmental variables produce insufficient classifier accuracy. Recent studies highlight the involvement of common genetic variants in length of pregnancy. This project involves the development of a risk score for preterm birth based on both genetic and environmental attributes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Global Interconnections Project (application closed)</title>
      <link>/2018/01/project-global-interconnections-project-application-closed/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/project-global-interconnections-project-application-closed/</guid>
      <description>&lt;p&gt;Understand interconnected nature of global multi-national companies via their supply chain, product and services competition, co-investments and co-ownerships as well as other dependencies between operations and revenue streams. We would like to consider the way news on any company specifically propagate down the connection graph and impact other businesses that are related in a way that is not necessarily explicit.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Modeling Genomic Evolution with Machine Learning</title>
      <link>/2018/01/project-modeling-genomic-evolution-with-machine-learning/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/project-modeling-genomic-evolution-with-machine-learning/</guid>
      <description>&lt;p&gt;A &lt;strong&gt;Fall 2018&lt;/strong&gt; internship is available in the Eaton lab to work on the development and application of machine learning approaches to historical evolutionary inference. Research will involve learning to use high performance distributed computing infrastructure, performing population genetic simulations, fitting machine learning models, and writing reproducible shareable code. The ideal candidate will have experience and interest in Python coding and a reasonable understanding of linear algebra.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Real-time brain state classification</title>
      <link>/2018/01/project-real-time-brain-state-classification/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/project-real-time-brain-state-classification/</guid>
      <description>&lt;p&gt;Using machine learning to conduct brain state classification at real-time on EEG/fNIRS/fMRI data.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Analysis pipeline for strain-level microbiome shotgun sequencing</title>
      <link>/2018/01/project-analysis-pipeline-for-strain-level-microbiome-shotgun-sequencing/</link>
      <pubDate>Sun, 21 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/project-analysis-pipeline-for-strain-level-microbiome-shotgun-sequencing/</guid>
      <description>&lt;p&gt;DNA sequence reads from a community of microbial genomes are currently processed without considering sequence variants. The project involves building a processing pipeline of such billions of short reads, identifying closest strains they might belong to, assembling them into specific clones, calling their variants, and analyzing the dynamic nature of these bacterial strains along sampling points.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Healthcare data analytics internship</title>
      <link>/2018/01/project-healthcare-data-analytics-internship/</link>
      <pubDate>Sun, 21 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/project-healthcare-data-analytics-internship/</guid>
      <description>&lt;p&gt;Recently Columbia University, Cornell, and NewYork-Presbyterian have agreed to integrate their clinical (healthcare) and business IT systems onto one shared platform called Epic. The motivating factors to move to Epic are to enhance the patient experience, improve and integrate care, and give our physicians an integrated technology platform that supports the mission of an academic medical center. The intern will assist with developing the “operational” analytics capabilities of Columbia University Medical Center including financial, healthcare operations and healthcare quality analytics.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project: Visual-tactile geometric reasoning</title>
      <link>/2018/01/project-visual-tactile-geometric-reasoning/</link>
      <pubDate>Sun, 21 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/project-visual-tactile-geometric-reasoning/</guid>
      <description>&lt;p&gt;Robotic grasp planning based on raw sensory data is difficult due to occlusion and incomplete scene geometry.  Often one sensory modality does not provide enough context to enable reliable planning.  A single depth sensor image cannot provide information about occluded regions of an object, and tactile information is incredibly sparse spatially.  We are building a Deep Learning CNN that combines both 3D vision and tactile information to perform shape completion of an object seen from a single view only, and plan stable grasps on these completed models.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
